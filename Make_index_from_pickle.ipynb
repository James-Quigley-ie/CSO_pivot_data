{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6d18e52a-22a3-4d94-9f44-ca546f0960e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "410a60c4-2a4e-44ab-957d-b9b1b3fd8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(x):\n",
    "    # Ensure x is a string\n",
    "    if not isinstance(x, str):\n",
    "        x = str(x)\n",
    "    \n",
    "    try:\n",
    "        # Handle patterns like \"YYYY/YY\" (e.g. \"2023/24\")\n",
    "        match_slash = re.search(r'(\\d{4})/(\\d{2})', x)\n",
    "        if match_slash:\n",
    "            full_year = match_slash.group(1)\n",
    "            short_year = match_slash.group(2)\n",
    "            year_candidate = int(full_year[:2] + short_year)\n",
    "            if not (1900 <= year_candidate <= 2262):\n",
    "                return pd.NaT\n",
    "            return pd.to_datetime(f\"{year_candidate}-01-01\")\n",
    "        \n",
    "        # Handle quarter patterns like \"YYYYQ[1-4]\" (e.g. \"2024Q4\")\n",
    "        match_quarter = re.search(r'(\\d{4})Q([1-4])', x)\n",
    "        if match_quarter:\n",
    "            year_candidate = int(match_quarter.group(1))\n",
    "            if not (1900 <= year_candidate <= 2262):\n",
    "                return pd.NaT\n",
    "            return pd.to_datetime(f\"{year_candidate}-01-01\")\n",
    "        \n",
    "        # Handle month patterns like \"YYYYM\\d{2}\" (e.g. \"2004M01\" or \"2010M12\")\n",
    "        match_month = re.search(r'(\\d{4})M(\\d{2})', x)\n",
    "        if match_month:\n",
    "            year_candidate = int(match_month.group(1))\n",
    "            if not (1900 <= year_candidate <= 2262):\n",
    "                return pd.NaT\n",
    "            return pd.to_datetime(f\"{year_candidate}-01-01\")\n",
    "        \n",
    "        # Fallback: Extract all 4-digit numbers\n",
    "        years = re.findall(r\"\\d{4}\", x)\n",
    "        if years:\n",
    "            # Filter out years that are not in a reasonable range\n",
    "            valid_years = [int(y) for y in years if 1900 <= int(y) <= 2262]\n",
    "            if valid_years:\n",
    "                max_year = max(valid_years)\n",
    "                return pd.to_datetime(f\"{max_year}-01-01\")\n",
    "    except (ValueError, OverflowError, pd.errors.OutOfBoundsDatetime):\n",
    "        return pd.NaT\n",
    "    \n",
    "    return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "61413ca1-801d-459a-84f0-0d044913bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_17524\\4084037481.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['latest', 'earliest']] = df[['latest', 'earliest']].applymap(convert_date)\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_pickle(\"cso_table.pkl\")\n",
    "\n",
    "# Convert 'latest' and 'earliest' using the convert_date function\n",
    "df[['latest', 'earliest']] = df[['latest', 'earliest']].applymap(convert_date)\n",
    "\n",
    "# Drop rows with missing dates in either column\n",
    "df.dropna(subset=['latest', 'earliest'], inplace=True)\n",
    "\n",
    "# Define the cutoff date and filter rows\n",
    "cutoff_date = pd.to_datetime(\"2022-01-01\")\n",
    "df = df.loc[df['latest'] >= cutoff_date].copy()\n",
    "\n",
    "# Convert lists in 'variables' to tuples of lowercase strings\n",
    "df['variables_tuple'] = df['variables'].apply(lambda x: tuple(item.lower() for item in x))\n",
    "\n",
    "# Create a new column with the lowercase version of 'table_name'\n",
    "df['table_name_lower'] = df['table_name'].str.lower()\n",
    "\n",
    "# Sort: 'latest' descending, 'earliest' ascending\n",
    "df.sort_values(by=['latest', 'earliest'], ascending=[False, True], inplace=True)\n",
    "\n",
    "# Drop duplicates based on the lowercased 'variables' and 'table_name'\n",
    "result_df = df.drop_duplicates(subset=['variables_tuple', 'table_name_lower'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "799a6781-332f-470e-8859-5278a8a2c331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f010b768d9841cf99ca07e63e20d3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 3753 docs → vector_index.faiss\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION\n",
    "INDEX_PATH  = \"vector_index.faiss\"\n",
    "META_PATH   = \"metadata.pkl\"\n",
    "MODEL_NAME  = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "EMBED_DIM   = 384  # model output dimension\n",
    "\n",
    "# Assume your DataFrame is already loaded as \"table\"\n",
    "# Use the 'table_name' column (or any desired column) as the document text.\n",
    "docs = result_df['table_name'].astype(str).tolist()\n",
    "\n",
    "\n",
    "metadata = result_df.apply(lambda row: {\n",
    "    \"table_id\": str(row.name),\n",
    "    \"table_name\": row[\"table_name\"],\n",
    "    \"fields\": row[\"variables\"],\n",
    "    \"earliest\": str(row[\"earliest\"].year),\n",
    "    \"latest\": str(row[\"latest\"].year),  # added latest\n",
    "    \"frequency\": row[\"frequency\"],\n",
    "}, axis=1).tolist()\n",
    "\n",
    "# 1 Embed the documents\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "embeddings = model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "# 2 Build the FAISS index\n",
    "index = faiss.IndexFlatL2(EMBED_DIM)\n",
    "index.add(embeddings)\n",
    "\n",
    "# 3 Save the index and metadata\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "with open(META_PATH, \"wb\") as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(f\"Indexed {len(docs)} docs → {INDEX_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2d6fe-f8fd-4e76-a9d7-1411670467c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f7bc1-dee7-4368-92b9-a93e0b18d404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908474da-7802-48fb-aca1-e716fe72c346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
